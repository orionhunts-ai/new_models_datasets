{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orionhunts-ai/new_models_datasets/blob/main/morpheus_cyber_gpt4o_mini_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Log Config { form-width: \"50px\" }\n",
        "%pip -qqq install loguru\n",
        "import os\n",
        "import sys\n",
        "from loguru import logger\n",
        "logger = logger\n",
        "LEVEL=\"DEBUG\"\n",
        "\n",
        "BASE_URL = os.environ.get(\"BASE_URL\", level=LEVEL)\n",
        "\n",
        "def config_logs(log_file_path = f\"{BASE_URL}logs/\"):\n",
        "  # Create log directory if it doesn't exist\n",
        "  os.makedirs(log_file_path, exist_ok=True)\n",
        "\n",
        "  # Remove the default logger\n",
        "  logger.remove()\n",
        "\n",
        "  # Add console handler with color\n",
        "  logger.add(\n",
        "      sys.stderr,\n",
        "      format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \"\n",
        "            \"<level>{level: <8}</level> | \"\n",
        "            \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - \"\n",
        "            \"<level>{message}</level>\",\n",
        "      level=LEVEL\n",
        "      colorize=True,\n",
        "  )\n",
        "\n",
        "  # Add file handler with color (use ansi=True to keep color codes in the file)\n",
        "  logger.add(\n",
        "      log_file_path,\n",
        "      format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \"\n",
        "            \"<level>{level: <8}</level> | \"\n",
        "            \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - \"\n",
        "            \"<level>{message}</level>\",\n",
        "      level=\"DEBUG\",\n",
        "      colorize=True,  # Ensure the colors are preserved in the log file\n",
        "      rotation=\"10 MB\",  # Rotate logs every 10 MB\n",
        "      retention=\"10 days\",  # Keep logs for 10 days\n",
        "      compression=\"zip\",  # Compress logs\n",
        ")\n",
        "\n",
        "# Example log messages\n",
        "logger.debug(\"This is a debug message.\")\n",
        "logger.info(\"This is an info message.\")\n",
        "logger.warning(\"This is a warning message.\")\n",
        "logger.error(\"This is an error message.\")\n",
        "logger.critical(\"This is a critical message.\")"
      ],
      "metadata": {
        "id": "e8lQrjyAUwry",
        "outputId": "c1c5b88b-c5f9-482a-8356-c6a07533c7d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-77-ce69e5937aa3>, line 25)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-77-ce69e5937aa3>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    level=LEVEL\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "UQBEi9hbiuZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f097f4-a0e7-443e-8d78-8e1c7651196d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-07-26 19:01:52.438\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 4>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[31m\u001b[1m'str' object is not callable\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# @title Install Core Libraries { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "\n",
        "if RUNS == 0:\n",
        "  try:\n",
        "    %pip -qqq install -U uuid typing requests pyarrow\n",
        "    %pip install -qqq torch\n",
        "    %pip install -qqq transformers datasets wandb huggingface_hub\n",
        "    _logger.info(\"Installed libs\")\n",
        "    RUNS += 1\n",
        "  except Exception as e:\n",
        "    _logger.error(e)\n",
        "    RUNS==0\n",
        "    pass\n",
        "else:\n",
        "  pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQrXn-C5brQr"
      },
      "source": [
        "# Fine Tuning OpenAI GPT-4o-Mini For (Free) Agentic\n",
        "\n",
        "*   476 Training Examples\n",
        "*   Cyber focused to assist with labelling threats\n",
        "\n",
        "Cyber üëæ\n",
        "\n",
        "  *  Training (and reporting) on Google Colab\n",
        "   for access to their high powered CUDA and  \n",
        "  Leveraging\n",
        "    * fine tuning on dataset ```\"swaption2009/cyber-threat-intelligence-custom-data‚Äù```\n",
        "    * Open AI offering this mini version of the already efficient gpt4o.\n",
        "        * OAI claims that the mini is almost as performant (but it's 20x cheaper)\n",
        "    * Sampling from the full set for those that are most relevant to Cyber Security Analysts.***\n",
        "\n",
        "    * Aside from traditional and evolving Evaluations I will also deploy a number of the finely tuned models in a Microsoft Autogen agentic environment to see how they perform on basic analysis on a database.\n",
        "\n",
        "    * ```Red Panda``` (a high performance streaming data alternative to ```Kafka``` will be used)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nymT8z2_noL9"
      },
      "source": [
        "## What about Phi!?!\n",
        "The last experiment with Phi is still ongoing. I am having CUDA compatibility issues between the librares and it's a good chance to learn a bit deeper into that stack\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auy20cWWddxV"
      },
      "source": [
        "##  Data and Tool Preparation\n",
        "**Summary:**\n",
        "\n",
        "This study explores the fine-tuning of the Phi-3-small-instruct model (7.39 billion parameters) by using Daniel So's Unsloth for a Cyber Threat Intelligence (CTI) task using methods like Parameter-Efficient Fine-Tuning (PEFT), Low-Rank Adaptation (LoRA), and Quantized Low-Rank Adaptation (QLoRA). It aims to evaluate performance degradation, model collaboration in agentic environments, and the potential influence of GPT-4. Synthetic data from gretel.ai was also utilized to supplement the fine-tuning process and enhance data diversity and robustness."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "VERSION = userdata.get('__VERSION__')\n",
        "BASE_URL = userdata.get('__BASE_URL__')\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "pretrained = \"gpt4o-mini\"\n",
        "project_type = \"fine_tuning\"\n",
        "orion_type = \"cyber\"\n",
        "model_name = f'{project_type}-{pretrained}-{orion_type}.Vx0'\n",
        "DATASET = \"swaption2009/cyber-threat-intelligence-custom-data\"\n",
        "\n",
        "os.chdir(BASE_URL)\n",
        "if project_type == None:\n",
        "  project_type = \"snyata\"\n",
        "else:\n",
        "  project_type=project_type\n",
        "\n",
        "project_name = f\"orion-intel-{pretrained}-{project_type}-x0\"\n",
        "model_name = project_name\n",
        "\n",
        "_project_stats = (f'''\n",
        "                  #### HELLO_HUMAN_ ######\n",
        "                  RUNS: {RUNS}\n",
        "                  PWD: {os.getcwd()}\n",
        "                  VERSION: {VERSION}\n",
        "                  PROJECT: {project_name}\n",
        "                  BASE_URL: {BASE_URL}\n",
        "                  DATA_URL  f'./data/'\n",
        "                  MODEL_URL: f'./models/'\n",
        "                  PRETRAINED: {pretrained}\n",
        "                  PROJECT_TYPE: {project_type}\n",
        "                  ########\n",
        "                  PROJECT NAME: {project_name}\n",
        "                  MODEL_NAME:  {model_name}\n",
        "                  DATASET: {DATASET} ''')\n",
        "_logger.info=_project_stats\n",
        "print(_project_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI4kmCmR-bv6",
        "outputId": "bed7f8c9-9944-495e-bf20-822a34cfc97a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                  #### HELLO_HUMAN_ ######\n",
            "                  RUNS: 0\n",
            "                  PWD: /content/drive/MyDrive/models_datasets\n",
            "                  VERSION: 0.1.0 \n",
            "                  PROJECT: orion-intel-gpt4o-mini-fine_tuning-x0\n",
            "                  BASE_URL: /content/drive/MyDrive/models_datasets/\n",
            "                  DATA_URL  f'./data/'\n",
            "                  MODEL_URL: f'./models/'\n",
            "                  PRETRAINED: gpt4o-mini\n",
            "                  PROJECT_TYPE: fine_tuning\n",
            "                  ########\n",
            "                  PROJECT NAME: orion-intel-gpt4o-mini-fine_tuning-x0\n",
            "                  MODEL_NAME:  orion-intel-gpt4o-mini-fine_tuning-x0\n",
            "                  DATASET: swaption2009/cyber-threat-intelligence-custom-data \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bAge5bNlyMg",
        "outputId": "b54871c1-2678-457a-98d4-a4c4bf8c0497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# IMPORTS\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import wandb\n",
        "from typing import List, Dict, Union, Optional\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "from google.colab import userdata\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import pyarrow\n",
        "import random\n",
        "!wandb login $WANDB_API_KEY\n",
        "\n",
        "# WANDB CONFIG\n",
        "os.environ[\"WANDB_PROJECT\"] = project_name\n",
        "os.environ[\"WANDB_API_KEY\"] = userdata.get('WANDB_API_KEY')\n",
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = f\"{os.path.dirname(os.path.abspath(os.path.expanduser(__name__)))}\"\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "hf_hub_key=userdata.get('HF_HUB_WRITE')\n",
        "wandb_key=userdata.get('WANDB_API_KEY')\n",
        "huggingface_hub.login(token=hf_hub_key, add_to_git_credential=True, write_permission=True)\n",
        "#notebook_login(new_session=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wandb_run(name, project_type, project=project_name):\n",
        "  try:\n",
        "    if wandb.run is None and os.environ[\"WANDB_MODE\"] != \"disabled\":\n",
        "      wandb.init(project=project, job_type=project_type, name=name)\n",
        "      project_init = wandb.init(project=project_name, job_type= \"data_preparation\" ,dir=f\"{BASE_URL}{project_name}/\")\n",
        "      _logger.info(f\"###WANDB_RUN:{wandb.run.name}###\")\n",
        "    elif os.environ[\"WANDB_MODE\"] == \"disabled\":\n",
        "      _logger.info(f\"##### WANDB DISABLED ### \")\n",
        "\n",
        "  except Exception as e:\n",
        "    _logger.error(e, exc_info=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "HhdotTZyMREf"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####PROJECT DEFINITION######\n",
        "model_prov = {\"openai\": f\"gpt4o-mini\",\n",
        "               \"mistral\": f\"mistral-7b\",\n",
        "               \"orion\": f\"orionai-cyber-{orion_type}-x0\"}\n",
        "\n",
        "model_prov=model_prov.get(\"orionai\")\n",
        "#_logger.info(f'MODEL PROVIDER: {model_prov}')\n",
        "\n",
        "args = TrainingArguments(\n",
        "    # other args and kwargs here\n",
        "    report_to=\"wandb\",  # enable logging to W&B\n",
        "    run_name=\"pre-processing-cyber\",  # name of the W&B run (optional)\n",
        "    logging_steps=5,\n",
        "    output_dir=BASE_URL)\n",
        "\n",
        "if wandb.run is None:\n",
        "  _logger.error(\"\"\"#### WANDB DISABLED \"\"\")\n",
        "  wandb_enable = input(\"Do you want to enable Weights and Biases?\")\n",
        "  if wandb_enable == \"yes\" or \"y\":\n",
        "    os.environ[\"WAND_MODE\"]=\"enabled\"\n",
        "    wandb.init(project=project_name, job_type=\"data_preparation\", dir=f\"{BASE_URL}{project_name}/\")\n",
        "  else:\n",
        "    _logger.info(wandb.mode)\n",
        "else:\n",
        "\n",
        "  _logger.info(f\"\"\"\n",
        "              ########## WANDB_RUN ########\n",
        "              RUNS: {RUNS}\n",
        "              NAME: {wandb.run.name}\n",
        "              OUTPUT_DIR: {BASE_URL}{project_name}/\n",
        "              MODEL: {model_prov}\n",
        "              DATASET: {DATASET}\n",
        "              ####### ###########\n",
        "                \"\"\")\n"
      ],
      "metadata": {
        "id": "YxsVhq2Balbv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "520fe958-d624-40c1-b770-72ed955db882"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'str' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-7e3eac792dbe>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   _logger.info(f\"\"\"\n\u001b[0m\u001b[1;32m     27\u001b[0m               \u001b[0;31m########## WANDB_RUN ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m               \u001b[0mRUNS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mRUNS\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The BSNS"
      ],
      "metadata": {
        "id": "8xf0H79jEJG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WandBArtifact():\n",
        "  def __init__(self, artifact_name, data, run=wandb.run, type=Union[\"data\", \"model\",\"table\"]):\n",
        "    self.run = run\n",
        "    self.artifact = artifact\n",
        "    self.type = type\n",
        "\n",
        "    if self.type == \"data\":\n",
        "      artifact = wandb.Table(dataframe=artifact_name, columns=[col for col in data.columns])\n",
        "\n",
        "    # Add the table to an Artifact to increase the row\n",
        "    # limit to 200000 and make it easier to reuse\n",
        "    new_artifact = wandb.Artifact(f\"{project}_{artifact_name}-{self.type}\", type=self.type)\n",
        "    artifact.add(data, artifact_name)\n",
        "\n",
        "    # log the raw csv file within an artifact to preserve our data\n",
        "    artifact.add_file(f\"{BASE_URL}/{model_name}.csv\")\n",
        "\n",
        "    # Start a W&B run to log data\n",
        "    run = f\"{project_name}-{random.randint(0,50)}-run\"\n",
        "    if wandb.run != run:\n",
        "      wandb.init(project=project, job_type=\"data_preparation\", name=run)\n",
        "    # Log the table to visualize with a run...\n",
        "    run.log({\"artifact_name\": f\"{artifact_name}\"})\n",
        "    run.log({\"job_type\": f\"{job_type}\"})\n",
        "    run.save()\n",
        "\n",
        "    # and Log as an Artifact to increase the available row limit!\n",
        "    run.log_artifact(new_artifact)\n",
        "    run.save()\n",
        "\n",
        "    _logger.info(f\"{artifact} MADE\\n\")"
      ],
      "metadata": {
        "id": "5gmFC2uKQy8s"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "xWDiksKlnZYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33fde55-5f18-4b4f-ba72-083f678fb30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###### DEVICE IS:  cuda:0\n"
          ]
        }
      ],
      "source": [
        "#ML Ops and EDA Imports\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Retrieve API keys from user data\n",
        "\n",
        "\n",
        "# Login to Weights & Biases\n",
        "'''if wandb_key:\n",
        "    wandb.login(key=wandb_key)\n",
        "else:\n",
        "    print(\"WANDB_API_KEY is not set\")\n",
        "\n",
        "Login to Hugging Face\n",
        "if hf_token:\n",
        "    os.system(f\"huggingface-cli login --token {hf_token} --add_to_git_credential\")\n",
        "    os.system(f\"huggingface-hub login --token {hf_token}\")\n",
        "else:\n",
        "     print(\"HF_TOKEN is not set\")'''\n",
        "\n",
        "# Check if cuda on Colab\n",
        "device = \"###### DEVICE IS:  cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a repo\n",
        "new_repo = False\n",
        "name=\"morpheus_cyber_gpt4o-mini\"\n",
        "if new_repo == False or huggingface_hub.repo_exists(repo_id=name):\n",
        "  pass\n",
        "  logger.info(f\"Repo {name} already exists\")\n",
        "else:\n",
        "  huggingface_hub.create_repo(repo_id=name)\n",
        "  logger.info(f\"Created repo {name}\")"
      ],
      "metadata": {
        "id": "qo-A6h3r6_6k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "370bc291-51c0-407a-a1c8-339575382083"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'str' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-e39542e2c809>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_repo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Repo {name} already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "cdfus0y8isnp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f82834ac892c431abe7822013c126ce0",
            "72d168cc729e4d8cb62eaeefef024443",
            "4acedea27780456e950a0737d76102a8",
            "99de622c529e4ec6b9887ee751f199ff",
            "a30a30900ff04a64b4097f7b6b3f8ff0",
            "3a145abca4b748a699a4757e19c7dfe6",
            "4d582e1a11874a39b3c1e8f295ca32f2",
            "b1be3d87fa864880b9dd1fa2964a30a7",
            "e5d7f507376e4ee5826116f8f8a786bc",
            "52bfe86a981f4034876afc6dd3bf58fc",
            "c900153801b44462a1c9040c543dd805",
            "62d53609428a43bda29255f681429e6c",
            "5c44fe28d498422d8ce285c7b145d36e",
            "895dcea02b9a49b4913a860a149b1ea6",
            "554b3054da304853b3964b02acb779f2",
            "a9d755e6780c46ec915f20d2178fb542",
            "d417d23b67074b6d8ac0b9c237e12dee",
            "e956c02111014b19a4ed384ebe707ba6",
            "e7583152e609442f89e523da1656f168",
            "8e8640c063b54906a972fc1402a822d3",
            "5f351673975b4ba9a8e6126cd3eedfe4",
            "8853d220d7a848688ba352787220735e",
            "abd9ee925c7145179f749ec68f2ceb2d",
            "7fde5772136d4250a1818d73932e9fdc",
            "72ad568cf8914ef19ff82b33868559cd",
            "79880035f72c456893bc4dfa13620900",
            "96f2868a0d134f219619242c8105885d",
            "14d082d3946043b2b9f4ac43bf9506a3",
            "1b3605def8e743daac25d5984e5fdb5d",
            "2b974d6a7da04cb59a7c8af4ae8b0570",
            "3835b431363d454d95e5674611633a71",
            "ca78d49634f04fdc951be76b8c5bcba8",
            "8bcc46bb333f49c4a2bd0938b342c498"
          ]
        },
        "outputId": "3279b6b6-8196-4fcb-899d-e7538fba4843"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/84.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f82834ac892c431abe7822013c126ce0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/685k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62d53609428a43bda29255f681429e6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/476 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abd9ee925c7145179f749ec68f2ceb2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-07-26 18:57:44.406\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[34m\u001b[1mDatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'text', 'entities', 'relations', 'diagnosis', 'solutions'],\n",
            "        num_rows: 476\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2024-07-26 18:57:44.411\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[34m\u001b[1m      id                                               text  \\\n",
            "0    249  A cybersquatting domain save-russia[.]today is...   \n",
            "1  14309  Like the Android Maikspy, it first sends a not...   \n",
            "2  13996  While analyzing the technical details of this ...   \n",
            "3  13600  (Note that Flash has been declared end-of-life...   \n",
            "4  14364  Figure 21. Connection of Maikspy variants to 1...   \n",
            "5  13565  The source code of this framework is shared ac...   \n",
            "6   2400  The CVE-2022-22965 vulnerability allows an att...   \n",
            "7  14126  At the same time, we were able to locate the M...   \n",
            "8   1929  But this link is further fortified by the Andr...   \n",
            "9   1921   A malicious RTF file that exploits the CVE-20...   \n",
            "\n",
            "                                            entities  \\\n",
            "0  [{'end_offset': 16, 'id': 44656, 'label': 'att...   \n",
            "1  [{'end_offset': 17, 'id': 48530, 'label': 'SOF...   \n",
            "2  [{'end_offset': 194, 'id': 48781, 'label': 'th...   \n",
            "3  [{'end_offset': 79, 'id': 51687, 'label': 'TIM...   \n",
            "4  [{'end_offset': 191, 'id': 51779, 'label': 'UR...   \n",
            "5  [{'end_offset': 63, 'id': 51646, 'label': 'loc...   \n",
            "6  [{'end_offset': 18, 'id': 45495, 'label': 'vul...   \n",
            "7  [{'end_offset': 79, 'id': 48192, 'label': 'loc...   \n",
            "8  [{'end_offset': 49, 'id': 45181, 'label': 'SOF...   \n",
            "9  [{'end_offset': 53, 'id': 47039, 'label': 'vul...   \n",
            "\n",
            "                                           relations  \\\n",
            "0  [{'from_id': 44658, 'id': 9, 'to_id': 44659, '...   \n",
            "1  [{'from_id': 48531, 'id': 445, 'to_id': 48532,...   \n",
            "2  [{'from_id': 48781, 'id': 461, 'to_id': 48782,...   \n",
            "3  [{'from_id': 51688, 'id': 1133, 'to_id': 51689...   \n",
            "4  [{'from_id': 51780, 'id': 1161, 'to_id': 44372...   \n",
            "5  [{'from_id': 51647, 'id': 1123, 'to_id': 51646...   \n",
            "6  [{'from_id': 45496, 'id': 105, 'to_id': 45495,...   \n",
            "7  [{'from_id': 48191, 'id': 392, 'to_id': 48192,...   \n",
            "8  [{'from_id': 45182, 'id': 80, 'to_id': 45183, ...   \n",
            "9  [{'from_id': 47045, 'id': 291, 'to_id': 47039,...   \n",
            "\n",
            "                                           diagnosis  \\\n",
            "0  The diagnosis is a cyber attack that involves ...   \n",
            "1  The diagnosis is that the entity identified as...   \n",
            "2  Diagnosis: APT37/Reaper/Group 123 is responsib...   \n",
            "3  The diagnosis is a malware infection. The enti...   \n",
            "4  The diagnosis is that Maikspy malware variants...   \n",
            "5  Possible diagnosis: Data Leakage  Explanation:...   \n",
            "6  The entity identified by ID 45495 is vulnerabl...   \n",
            "7  The cybersecurity issue is not specified in th...   \n",
            "8  The diagnosis is that Patchwork threat actor g...   \n",
            "9  The diagnosis is a malware infection resulting...   \n",
            "\n",
            "                                           solutions  \n",
            "0  1. Implementing DNS filtering to block access ...  \n",
            "1  1. Implementing a robust anti-malware software...  \n",
            "2  1. Implementing advanced threat detection tech...  \n",
            "3  1. Implementing a robust antivirus software th...  \n",
            "4  1. Implementing a robust firewall system that ...  \n",
            "5  1. Implement access controls: Restrict access ...  \n",
            "6  1. Patch the vulnerability: The most straightf...  \n",
            "7  Without a specific cybersecurity issue to addr...  \n",
            "8  1. Implementing strong network security measur...  \n",
            "9  1. Patching the vulnerabilities: The first and...  \u001b[0m\n",
            "\u001b[32m2024-07-26 18:57:44.415\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1m<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
            "\u001b[32m2024-07-26 18:57:44.416\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1m      id                                               text  \\\n",
            "0    249  A cybersquatting domain save-russia[.]today is...   \n",
            "1  14309  Like the Android Maikspy, it first sends a not...   \n",
            "2  13996  While analyzing the technical details of this ...   \n",
            "3  13600  (Note that Flash has been declared end-of-life...   \n",
            "4  14364  Figure 21. Connection of Maikspy variants to 1...   \n",
            "\n",
            "                                            entities  \\\n",
            "0  [{'end_offset': 16, 'id': 44656, 'label': 'att...   \n",
            "1  [{'end_offset': 17, 'id': 48530, 'label': 'SOF...   \n",
            "2  [{'end_offset': 194, 'id': 48781, 'label': 'th...   \n",
            "3  [{'end_offset': 79, 'id': 51687, 'label': 'TIM...   \n",
            "4  [{'end_offset': 191, 'id': 51779, 'label': 'UR...   \n",
            "\n",
            "                                           relations  \\\n",
            "0  [{'from_id': 44658, 'id': 9, 'to_id': 44659, '...   \n",
            "1  [{'from_id': 48531, 'id': 445, 'to_id': 48532,...   \n",
            "2  [{'from_id': 48781, 'id': 461, 'to_id': 48782,...   \n",
            "3  [{'from_id': 51688, 'id': 1133, 'to_id': 51689...   \n",
            "4  [{'from_id': 51780, 'id': 1161, 'to_id': 44372...   \n",
            "\n",
            "                                           diagnosis  \\\n",
            "0  The diagnosis is a cyber attack that involves ...   \n",
            "1  The diagnosis is that the entity identified as...   \n",
            "2  Diagnosis: APT37/Reaper/Group 123 is responsib...   \n",
            "3  The diagnosis is a malware infection. The enti...   \n",
            "4  The diagnosis is that Maikspy malware variants...   \n",
            "\n",
            "                                           solutions  \n",
            "0  1. Implementing DNS filtering to block access ...  \n",
            "1  1. Implementing a robust anti-malware software...  \n",
            "2  1. Implementing advanced threat detection tech...  \n",
            "3  1. Implementing a robust antivirus software th...  \n",
            "4  1. Implementing a robust firewall system that ...  \u001b[0m\n",
            "\u001b[32m2024-07-26 18:57:44.419\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[31m\u001b[1m0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Loading pre-determined Cyber Data - Create your own Synthetic data on top at https://gretel.ai/'''\n",
        "import pandas as pd\n",
        "try:\n",
        "  from datasets import load_dataset\n",
        "  ds = load_dataset(\"swaption2009/cyber-threat-intelligence-custom-data\")\n",
        "  logger.debug(ds)\n",
        "  df_train = ds['train'].to_pandas()\n",
        "  logger.debug(df_train[0:10])\n",
        "  logger.debug(type(df_train))\n",
        "  logger.debug(df_train.head())\n",
        "  logger.info({df_train[0]})\n",
        "\n",
        "except Exception as e:\n",
        "  logger.error(f'{e}', exc_info=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aTRxaRruwJ4"
      },
      "source": [
        "# Data Cleaning and NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "v0sAMqR0t31s"
      },
      "outputs": [],
      "source": [
        "#DropNA and Duplicates\n",
        "after_drop = df_train.dropna().drop_duplicates()\n",
        "after_drop.shape\n",
        "df_clean = after_drop.copy()\n",
        "#assert before_drop == after_drop.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "P9haUlm7uIzW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4a891012-ce6c-4413-cf30-ded4b03ae57d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# Reduce to the observation (data), the diagnosis, and mitigations. Split out the entities array to\n",
        "# mess around with graph based analysis later on.\n",
        "pre_process = wandb.init(name=\"pre-processing cyber\", project=project_name, job_type=\"pre-processing\")\n",
        "pre_data = wandb.Artifact(name=\"preprocessing_data\", type=\"dataset\")\n",
        "pre_process.log_artifact(pre_data)\n",
        "\n",
        "\n",
        "\n",
        "pre_process = wandb.Table(columns=[\"text\", \"diagnosis\",  \"solutions\"])\n",
        "#Add Artifact\n",
        "pre_table = wandb.log({\"table\": df_train})\n",
        "\n",
        "\n",
        "columns = [\"text\", \"diagnosis\", \"solutions\"]\n",
        "df_train = df_train[columns]\n",
        "wandb.log_artifact(pre_data, df_train)\n",
        "wandb.save()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "WGdQR8h0u1JR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e45ba3a-6cba-4770-d6a2-3c5c9fce44cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# nlp cleaning\n",
        "%pip install -qqq gensim nltk\n",
        "import nltk\n",
        "import gensim\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "\n",
        "def preprocess_text(text):\n",
        "  # Stop words remove Tokenize the text\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  filtered_sentence = [w for w in tokens if not w.lower() in stop_words and w.isalnum()]\n",
        "  filterered_sentence=\" \".join(filtered_sentence)\n",
        "\n",
        "  return filtered_sentence\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "mxMAXSlCv5qB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "077e0aae1b25438ca429d731dd980c27",
            "d17d9126bc3349549aa54d2c96f3b09e",
            "2e72689caa79421782caeb102860eb39",
            "0500f9571a6941029dfbb0ef573842e9",
            "8176a636edf24125beb39abde56db33a",
            "1a8907e67b594656ab4ad706f4b55da9",
            "8f7be7dced194d188646ad035a4019f9",
            "52cbfcf2c449409ba71b13aa8900ac74",
            "f3bf3637a1574c1ab27ee30cd046e0c1",
            "1b690c30e65e493b9e28c3840d67665d",
            "fb579b754b0e4fb7966956a2db25fc7a",
            "5c4900b089d848f6b1d85a863f593b13",
            "5d7bdf13531647cfbad0f83e53341682",
            "43b75bdaf780490986b89e4869782db9",
            "daeac61738644eecbd9c9531d449fa3c",
            "e6d869e58dbb4bea91926f2263ab4fc6",
            "c035efe94f3f4ce28d40a7d63aedd411",
            "793bfd2ea2e047e9b6f1066b849a1181",
            "0aadd29e0afa40b1875e07e9b2afac4e",
            "1b2ebfb8bdcd4a5ca51bb6d65cab9cda",
            "32b7d7628a2749b399fe4a7de92cfefb",
            "0dffe6cbe1f3429cb924a44622bb69a8",
            "c6f248eb6b814d119dba522ddec9745a",
            "e7169f98bfa34f29aba44c64982f0a2d",
            "bc957928ee25442aab5cf7c720dbb441",
            "d7bf2660d8d640ee88091a9748165d64",
            "a005ec56a1a04ae1b6337b85cdbaf4d3",
            "dc098ef691e44a168b1bc4de43eb43e8",
            "ee6a6a2a5f5d4bfcb5d5949d8bc5c32a",
            "4e30068c3abe4f6495471f9af8450540",
            "1f946490fd894258802b6339e4a3e696",
            "393cb25369254352b8ed9b5468f1be9b",
            "b3bee792942e4dd5af9c90589b5a72dd"
          ]
        },
        "outputId": "f422f698-fb4a-48d4-c515-47889cf43cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 476/476 [00:00<00:00, 2748.31it/s]\n",
            "<ipython-input-80-ef595c06a033>:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  df_scenario_outcome[\"text_pr\"] = tqdm_notebook(df_scenario_outcome[\"text\"].progress_apply(preprocess_text))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/476 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "077e0aae1b25438ca429d731dd980c27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 476/476 [00:00<00:00, 2092.40it/s]\n",
            "<ipython-input-80-ef595c06a033>:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  df_scenario_outcome[\"diagnosis_pr\"] = tqdm_notebook(df_scenario_outcome[\"diagnosis\"].progress_apply(lambda x: preprocess_text(x) if x is not None else ''))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/476 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c4900b089d848f6b1d85a863f593b13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 476/476 [00:00<00:00, 976.11it/s]\n",
            "<ipython-input-80-ef595c06a033>:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  df_scenario_outcome[\"solutions_pr \"] = tqdm_notebook(df_scenario_outcome[\"solutions\"].progress_apply(preprocess_text))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/476 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6f248eb6b814d119dba522ddec9745a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Tokenise and remove stopwords + Concatenate Scenario and Outcome\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "from tqdm import tqdm_notebook\n",
        "tqdm.pandas()\n",
        "df_scenario_outcome = df_train.copy()\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "#logger.info(device)\n",
        "try:\n",
        "    # Apply preprocessing function with progress bar\n",
        "    tqdm.pandas()\n",
        "    df_scenario_outcome[\"text_pr\"] = tqdm_notebook(df_scenario_outcome[\"text\"].progress_apply(preprocess_text))\n",
        "    df_scenario_outcome[\"diagnosis_pr\"] = tqdm_notebook(df_scenario_outcome[\"diagnosis\"].progress_apply(lambda x: preprocess_text(x) if x is not None else ''))\n",
        "    df_scenario_outcome[\"solutions_pr \"] = tqdm_notebook(df_scenario_outcome[\"solutions\"].progress_apply(preprocess_text))\n",
        "except Exception as e:\n",
        "  _logger.error(e, exc_info=True)\n",
        "  artifact = wandb.Artifact(name=\"pre_tokenisation\", type=\"dataset\")\n",
        "  pre_data.add(df_scenario_outcome, \"df_scenario_outcome\")\n",
        "  pre_data.log_artifact(artifact)\n",
        "  run.save()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'Error: {e}', file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Process Concat Field\n",
        "df_scenario_outcome[\"scenario_outcome\"] = df_scenario_outcome.progress_apply(\n",
        "    lambda row: 'Scenario: ' + str(row[\"text\"]) + ' Outcome: ' + str(row[\"diagnosis\"]), axis=1)"
      ],
      "metadata": {
        "id": "yivtaW7bbvoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b54a65-d642-4fdc-8266-10ddec0f51c2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 476/476 [00:00<00:00, 81227.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_scenario_outcome.columns\n",
        "df_scenario_outcome.isnull().drop(index=1, inplace=True)\n",
        "df_scenario_outcome.dropna(inplace=True)\n",
        "df_scenario_outcome.shape\n",
        "df_scenario_outcome.columns\n",
        "\n",
        "columns_to_drop = ['text', 'diagnosis', 'solutions']\n",
        "df_pp = df_scenario_outcome.copy().drop(columns, axis=1)\n",
        "df_pp.head()\n",
        "type(df_pp)"
      ],
      "metadata": {
        "id": "sHrvxvxzVnq5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "8477b957-9f69-4387-efb1-539e8341dace"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 490);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### LOG TRAINING ARTEFACT ###\n",
        "import random\n",
        "\n",
        "\n",
        "def log_model_artifact(artifact_type, ROOT_DIR=BASE_URL, project_name=project_name, model_name=model_name, run=wandb.run):\n",
        "  # Start a new W&B run\n",
        "  if run != wandb.run:\n",
        "    run = wandb.init(project=project_name, job_type=\"training\", name=f\"{model_name}\")\n",
        "\n",
        "  # Simulate logging model metrics\n",
        "  #run.log({\"acc\": random.random()}) #TODO ADD MORE METRICKS\n",
        "\n",
        "  # Create a simulated model file\n",
        "  with open(f\"{model_name}.h5\", \"w\") as f:\n",
        "      f.write(\"Model: \" + str(random.randomint()))\n",
        "\n",
        "  # Log and link the model to the Model Registry\n",
        "  reg_model = run.link_model(path=f\"{ROOT_DIR}models/{model_name}.h5\", registered_model_name=f'{model_name}')\n",
        "\n",
        "  # Finish the W&B run\n",
        "  wandb.run.save()\n",
        "\n"
      ],
      "metadata": {
        "id": "ULGrACkRLG5h"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### W&B config before Fine Tuning"
      ],
      "metadata": {
        "id": "CfAJyQyoEKsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Add the processed data to a WandB Table\n",
        "Add to Artifact\n",
        "'''\n",
        "%pip install -qq evaluate\n",
        "#NEW RUN\n",
        "training_art =\n",
        "train_run.Artifact(name=\"training_data\", type=\"dataset\", data=)\n",
        "train_run.save()\n",
        "morpheus_table = wandb.Table(dataframe=df_pp, columns=[\"scenario_outcome\", \"solutions_pr\"])\n",
        "wandb.log({\"table\": morpheus_table})\n",
        "\n"
      ],
      "metadata": {
        "id": "SeUJqXEuERkC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "18f7c281-b3cc-48c9-d6b0-3a62a38ba782"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'project' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-08d3cc2de79c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install -qq evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#NEW RUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmorpheus_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_pp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scenario_outcome\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"solutions_pr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"table\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmorpheus_table\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'project' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_model_artifact(project, \"model\")\n",
        "\n",
        "run.finish()\n"
      ],
      "metadata": {
        "id": "4H_gKcV8sXcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Processing Before Training\n",
        "GPU requires the data & model to be on the GPU (or at least the same device if not GPU) REF: Mac torch.backends.mps.available() rather than cuda"
      ],
      "metadata": {
        "id": "E6V2ZIXNplui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ENCODE CATEGORICAL VARIABLES\n",
        "def preprocess_dataframe(dataframe):\n",
        "    \"\"\"\n",
        "    Preprocess the DataFrame to ensure all data is numerical.\n",
        "    Convert non-numeric columns to numerical data or drop them.\n",
        "    \"\"\"\n",
        "    # Convert categorical columns to numerical data\n",
        "    df_encoded= pd.get_dummies(dataframe)\n",
        "    logger.info(\"Converted categorical columns to numerical\")\n",
        "\n",
        "    # Ensure all data is float32\n",
        "    df_encoded = df_encoded.astype(np.float32)\n",
        "    logger.info(\"Converted all data to float32\")\n",
        "\n",
        "    return df_encoded\n"
      ],
      "metadata": {
        "id": "tR8L1Zn1tktI"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ENCODE NOW\n",
        "df_encoded = df_pp.copy()\n",
        "for x in df_encoded.columns:\n",
        "  str(x)\n",
        "  df_encoded[x] = df_encoded.progress_apply(preprocess_dataframe)"
      ],
      "metadata": {
        "id": "Ryn5vcHPltit",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "62a09634-fc4a-46bf-c6f5-bbcd80ae91d2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00, 1018.03it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unhashable type: 'list'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(self, sort, use_na_sentinel)\u001b[0m\n\u001b[1;32m   1163\u001b[0m     ) -> tuple[npt.NDArray[np.intp], Index]:\n\u001b[0;32m-> 1164\u001b[0;31m         codes, uniques = algorithms.factorize(\n\u001b[0m\u001b[1;32m   1165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         codes, uniques = factorize_array(\n\u001b[0m\u001b[1;32m    781\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     uniques, codes = table.factorize(\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-623cef3910ee>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mdf_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9422\u001b[0m         )\n\u001b[0;32m-> 9423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9425\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-ef2965c11093>\u001b[0m in \u001b[0;36mpreprocess_dataframe\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Convert categorical columns to numerical data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf_encoded\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Converted categorical columns to numerical\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/encoding.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         result = _get_dummies_1d(\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/encoding.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize_from_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mfactorize_from_iterable\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   2574\u001b[0m         \u001b[0;31m# but only the resulting categories, the order of which is independent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m         \u001b[0;31m# from ordered. Set ordered to False as default. See GH #15457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2577\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                 \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0;31m# raise, as we don't have a sortable data structure and so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# should happen here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(self, sort, use_na_sentinel)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     ) -> tuple[npt.NDArray[np.intp], Index]:\n\u001b[0;32m-> 1164\u001b[0;31m         codes, uniques = algorithms.factorize(\n\u001b[0m\u001b[1;32m   1165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    778\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnull_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         codes, uniques = factorize_array(\n\u001b[0m\u001b[1;32m    781\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     uniques, codes = table.factorize(\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Utility function to convert a dataframe to a PyTorch tensor.\n",
        "- More important with large datasets to be on the GPU\n",
        "\"\"\"\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "_logger.info(f\"Data is on: {device}\")\n",
        "\n",
        "\n",
        "def to_numpy(dataframe):\n",
        "    \"\"\"\n",
        "    Convert a DataFrame to a numpy array with float32 dtype.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df_numpy = dataframe.to_numpy(dtype=np.float32)\n",
        "        _logger.info(\"Data is numpy array\")\n",
        "        _logger.info(f\"Shape of numpy array: {df_numpy.shape}\")\n",
        "        return df_numpy\n",
        "    except Exception as e:\n",
        "        _logger.error(f'Error converting DataFrame to numpy array: {e}', exc_info=True)\n",
        "\n",
        "def df_to_tensor(df_numpy, device=device):\n",
        "    \"\"\"\n",
        "    Convert a numpy array to a PyTorch tensor and move it to the specified device.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df_tensors = torch.tensor(df_numpy, dtype=torch.float32)\n",
        "        _logger.info(\"Data is PyTorch tensor with dtype torch.float32\")\n",
        "        df_tensors = df_tensors.to(device)\n",
        "        _logger.info(f\"Data is on {device}\")\n",
        "        return df_tensors\n",
        "    except Exception as e:\n",
        "        _logger.error(f'Error converting numpy array to PyTorch tensor: {e}', exc_info=True)\n"
      ],
      "metadata": {
        "id": "hoJ7ZtD_mG07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcglASnz7D9n"
      },
      "outputs": [],
      "source": [
        "# Convert DataFrame to numpy array\n",
        "df_numpy = to_numpy(df_scenario_outcome)\n",
        "_logger.debug(df_numpy)\n",
        "\n",
        "# Convert numpy array to PyTorch tensor\n",
        "df_tensor = df_to_tensor(df_numpy)\n",
        "_logger.debug(df_tensor)\n",
        "\n",
        "# Logging the shape of the tensor\n",
        "_logger.info(f\"Shape of tensor: {df_tensor.shape}\")\n",
        "\n",
        "# Verify the type of df_tensor\n",
        "_logger.info(f\"Type of df_tensor: {type(df_tensor)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_table = wandb.Table(dataframe=df_scenario_outcome, columns=[\"scenario_outcome\", \"solutions_pr\"])\n",
        "\n",
        "table_plot = run.plot_table(data_table=data_table,fields=[\"scenario_outcome\",\"solutions\"], vega_spec_name={project})\n",
        "run.save()\n",
        "plt.show(table_plot)\n",
        "run.log({f\"table_pot\": f\"{wandb.Graph(table_plot)}\"})\n",
        "wandb.save()"
      ],
      "metadata": {
        "id": "pYM_vlsUeiJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model Registry { run: \"auto\" }\n",
        "#huggingface_hub.login(token=HF_HUB, add_to_git_credential=True, write_permission=True)\n",
        "# Start a new W&B run\n",
        "run_name = f\"{project}-save_model\"\n",
        "\n",
        "def check_run(run_name):\n",
        "  if wandb.run is None:\n",
        "    wandb.init(project=project, job_type=\"model\", name=run_name)\n",
        "  else:\n",
        "    wandb.run.finish()\n",
        "    wandb.init(project=project, job_type=\"model\", name=run_name)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KWxnTqSWux0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_log(save_model: bool = False):\n",
        "      wandb.run.name.log({\"acc\": acc})\n",
        "\n",
        "    # Model File\n",
        "    if os.path.exists(f\"{BASE_URL}/{project}/models/\") == False:\n",
        "      os.mkdir(f\"{BASE_URL}/{project}/models/\")\n",
        "      run.link_model(path=f\"{BASE_URL}/{project}/models/{model_name}.h5\", registered_model_name=model_name)\n",
        "      run.save()\n",
        "      with open(f\"{BASE_URL}/{project}/models/{model_name}.h5\", \"w\") as f:\n",
        "        f.write(\"Model: \" + str(random.random()))\n",
        "      run.finish()"
      ],
      "metadata": {
        "id": "m76rPsRKZk85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uuid for files\n",
        " import uuid\n",
        "id = str(uuid.uuid4())[0:6]\n",
        "print(id)"
      ],
      "metadata": {
        "id": "JKQhG5xr0Is4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9uHBauE6YYI"
      },
      "outputs": [],
      "source": [
        "'''Sentiment Analysis:\n",
        "Added in some meta data to match the Scenario as outlined in the initial text column mapping it\n",
        "to a scenario, and outcome. Then asking for the sentiment of the solutions'''\n",
        "\n",
        "import wandb\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoConfig\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install -qqq transformers torch accelerate\n",
        "\n",
        "# Initialize W&B run for sentiment job\n",
        "training_run = wandb.init(project=project, name=f\"Sentiment_Analysis_{id}\",\n",
        "                 job_type=\"sentiment\",dir=\"/content/drive/MyDrive/models_datasets/models\")\n",
        "\n",
        "\n",
        "# Define model and tokenizer\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "#####\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL, output_hidden_states=True)\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device)\n",
        "wandb.log({\"object\": classifier})\n",
        "# Define paths and names\n",
        "project = project\n",
        "model_id = \"sentiment_model\"\n",
        "model_name = f\"{project}-cyber{model_id}\"\n",
        "model_path = f\"./content/drive/MyDrive/models_datasets/models/\"\n",
        "\n",
        "# Save the model\n",
        "check_point = classifier.save_pretrained(model_name)\n",
        "wandb.save(check_point)\n",
        "\n",
        "# Initialize a new W&B run to store the model\n",
        "\n",
        "\n",
        "# Create a new artifact and add the model file to it\n",
        "artifact = wandb.Artifact(name=f'{model_name}', type=\"model\")\n",
        "training_run.save()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_sentiment = df_scenario_outcome.copy()\n",
        "df_sentiment.drop([\"text\", \"diagnosis\", \"solutions\"], axis=1)\n",
        "print(df_sentiment.shape)\n",
        "\n",
        "#Make a data table from a dataframe\n",
        "data_table = wandb.Table(dataframe=df_sentiment)\n",
        "table_plot = wandb.plot_table(data_table=data_table,fields=[\"text\",\"diagnosis\",\"solutions\"], vega_spec_name={project})\n",
        "wandb.run.save()\n",
        "plt.show(table_plot)\n",
        "run.log({f\"table_pot\": f\"{wandb.Graph(table_plot)}\"})"
      ],
      "metadata": {
        "id": "p50rUr1DemBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Visualize in Weights and biases form everything until here\n",
        "\n",
        "# Assuming 'run' is your active wandb run object\n",
        "\n",
        "# Log summary metrics\n",
        "wandb.run.summary[\"num_samples\"] = len(df_scenario_outcome)\n",
        "wandb.run.summary[\"num_unique_diagnoses\"] = df_scenario_outcome[\"diagnosis\"].nunique()\n",
        "# Add other relevant summary stats\n",
        "\n",
        "# Log the preprocessed dataframe as a table\n",
        "preprocessed_table = wandb.Table(dataframe=df_pp,\n",
        "                                 columns=[\"scenario_outcome\", \"solutions_pr\"])\n",
        "wandb.run.log({\"preprocessed_data\": preprocessed_table})\n",
        "\n",
        "# Log the sentiment analysis results (assuming you have a df_sentiment with results)\n",
        "sentiment_table = wandb.Table(dataframe=df_sentiment,\n",
        "                               columns=[\"scenario_outcome\", \"solutions_pr\", \"sentiment\"])\n",
        "wandb.run.log({\"sentiment_analysis_results\": sentiment_table})\n",
        "\n",
        "# Log the table plot you created earlier\n",
        "wandb.run.log({\"data_visualization\": wandb.Image(table_plot)})\n",
        "\n",
        "# Optionally log histograms of text lengths, word frequencies, etc.\n",
        "# ...\n",
        "\n",
        "# Finish the run\n",
        "wandb.run.save()\n"
      ],
      "metadata": {
        "id": "QFbLgOrg2Afg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44ISKprQ7Rbj"
      },
      "outputs": [],
      "source": [
        "# Function to predict sentiment\n",
        "import scipy\n",
        "\n",
        "\n",
        "_logger.info(device)\n",
        "\n",
        "def predict_sentiment(text=df_sentiment, model=model, classifier=classifier):\n",
        "  model.to(device)\n",
        "  if text is not None:\n",
        "      labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "      from scipy.special import softmax\n",
        "      encoded_input = tokenizer(text, return_tensors='pt', truncation=True).to(device)\n",
        "      # Run the model\n",
        "      #with torch.no_grad(\n",
        "      output = model(**encoded_input)\n",
        "      # Extract the sentiment scores\n",
        "      scores = output[0][0].detach().numpy()\n",
        "      scores = softmax(scores)\n",
        "      # Truncate the text to the maximum length the model can handle\n",
        "\n",
        "      result = classifier(scores)\n",
        "      ranking = np.argsort(result)\n",
        "      ranking = ranking[::-1]\n",
        "      for i in range(scores.shape[0]):\n",
        "        l = labels[ranking[i]]\n",
        "        s = scores[ranking[i]]\n",
        "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
        "      return sentiment, label\n",
        "\n",
        "## Apply to copied DF\n",
        "sentiment = df_sentiment['scenario_outcome'].progress_apply(predict_sentiment)\n",
        "#score = df_sentiment[\"scenario_outcome\"].progress_apply(predict_sentiment)\n",
        "#df_sentiment['sentiment'] = sentiment[0]\n",
        "#df_sentiment['score'] = sentiment[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.link_model(\n",
        "    path=model_path,\n",
        "    registered_model_name=f\"{model_name}\",\n",
        "    name=\"4o-mini-cyber\",\n",
        "    aliases=[\"gpt4omini, finetune\"],\n",
        ")"
      ],
      "metadata": {
        "id": "ex4UNz2rUREa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER for enriching the data more ###"
      ],
      "metadata": {
        "id": "bM8GYnxugR31"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwgGP3lq6xIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "At-hc4nq51Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "artifact = wandb.Artifact(name=f'{model_name}', type=\"model\")\n",
        "artifact.add_file(local_path=\"./content/drive/MyDrive/models_datasets/models/\", name=f'{local-path}-NER')\n",
        "ner_model = 'dslim/bert-base-NER'\n",
        "ner_tokenizer = AutoTokenizer.from_pretrained(ner_model)\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(ner_model)\n",
        "\n",
        "# Log the artifact to W&B\n",
        "run.log_artifact(artifact)\n",
        "huggingface_hub.save_pretrained_torch(model, model_name)\n",
        "# Finish the W&B run\n",
        "run.save()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i5ieCvXrRKnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J22VUEDugIeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "19Wpt1f7Jl2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBGKfe2t6HPB"
      },
      "outputs": [],
      "source": [
        "'''Sentiment Analysis:\n",
        "Added in some meta data to match the Scenario as outlined in the initial text column mapping it\n",
        "to a scenario, and outcome. Then asking for the sentiment of the solutions'''\n",
        "\n",
        "import wandb\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoConfig\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install -qqq transformers torch accelerate\n",
        "\n",
        "# Initialize W&B run for sentiment job\n",
        "training_run = wandb.init(project=project, name=f\"Sentiment_Analysis_{id}\",\n",
        "                 job_type=\"sentiment\",dir=\"/content/drive/MyDrive/models_datasets/models\")\n",
        "\n",
        "\n",
        "# Define model and tokenizer\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "#####\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL, output_hidden_states=True)\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device)\n",
        "wandb.log({\"object\": classifier})\n",
        "# Define paths and names\n",
        "project = project\n",
        "model_id = \"sentiment_model\"\n",
        "model_name = f\"{project}-cyber{model_id}\"\n",
        "model_path = f\"./content/drive/MyDrive/models_datasets/models/\"\n",
        "\n",
        "# Save the model\n",
        "check_point = classifier.save_pretrained(model_name)\n",
        "wandb.save(check_point)\n",
        "\n",
        "# Initialize a new W&B run to store the model\n",
        "\n",
        "\n",
        "# Create a new artifact and add the model file to it\n",
        "artifact = wandb.Artifact(name=f'{model_name}', type=\"model\")\n",
        "training_run.save()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_sentiment = df_scenario_outcome.copy()\n",
        "df_sentiment.drop([\"text\", \"diagnosis\", \"solutions\"], axis=1)\n",
        "print(df_sentiment.shape)\n",
        "\n",
        "#Make a data table from a dataframe\n",
        "data_table = wandb.Table(dataframe=df_sentiment)\n",
        "table_plot = wandb.plot_table(data_table=data_table,fields=[\"text\",\"diagnosis\",\"solutions\"], vega_spec_name={project})\n",
        "wandb.run.save()\n",
        "plt.show(table_plot)\n",
        "run.log({f\"table_pot\": f\"{wandb.Graph(table_plot)}\"})"
      ],
      "metadata": {
        "id": "tAFLIpBu6HPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byNGgFWwuslR"
      },
      "outputs": [],
      "source": [
        "### Text-Diagnosis Concatenation & HotEncoder Target\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "# FIX THIS\n",
        "df_encoded = df_tokenized.copy()\n",
        "df_encoded['text_diagnosis'] = df_text_diagnosis['text_processed'] + df_text_diagnosis['diagnosis_processed']\n",
        "\n",
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Word to Vec Model"
      ],
      "metadata": {
        "id": "dEvCvh_21lSs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6Jx6hB1wnbT"
      },
      "outputs": [],
      "source": [
        "# Train a Word2Vec model (example)\n",
        "apply_word2Vec[column for column in columns]\n",
        "model = Word2Vec(df_domains['text_processed'], min_count=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-mlASTCxkUt"
      },
      "outputs": [],
      "source": [
        "# Apply the function to each column\n",
        "df_w2v = df_domains.copy()\n",
        "df_w2v['text_processed'] = df_domains['text'].apply(preprocess_text)\n",
        "df_w2v['diagnosis_processed'] = df_domains['diagnosis'].apply(preprocess_text)\n",
        "df_w2v['solutions_processed'] = df_domains['solutions'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nc_r5PHQTNkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Embeddings with Gpt4o-Mini finely tuned and using the small OAI # Embeddings"
      ],
      "metadata": {
        "id": "Mcq00DdlGi_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n"
      ],
      "metadata": {
        "id": "OvnzvBvE14Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHi7I5ShwqXO"
      },
      "outputs": [],
      "source": [
        "\n",
        "openai.api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "oai_model=\"text-embedding-3-small\"\n",
        "\n",
        "def get_openai_embedding(text,engine=oai_model):\n",
        "    response = openai.Embedding.create(\n",
        "      input=text,\n",
        "      engine=engine  # Or another model you prefer\n",
        "    )\n",
        "    return response['text'][0]['embedding']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_data_oai.columns"
      ],
      "metadata": {
        "id": "Acd2KR1qB0v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX8fJQPjv3Pm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_data_oai = df_encoded.copy()\n",
        "embedded_data_oai['text_embedding'] = embedded_data_oai[''].progress_apply(get_openai_embedding)"
      ],
      "metadata": {
        "id": "as0dkTZXJs-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Start a new run for visualizations\n",
        "viz_run = wandb.init(project=\"morpheus_cyber_gpt-4o-mini\", job_type=\"visualization\")\n",
        "\n",
        "# --- Distribution of Sentiment ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df_sentiment, x='sentiment')\n",
        "plt.title('Distribution of Sentiment')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "# Log the plot to W&B\n",
        "viz_run.log({\"sentiment_distribution\": wandb.Image(plt)})\n",
        "plt.show()\n",
        "\n",
        "# --- Word Cloud of Text ---\n",
        "from wordcloud import WordCloud\n",
        "text_corpus = ' '.join(df_scenario_outcome['text_pr'].astype(str).tolist())\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_corpus)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud of Text Data')\n",
        "# Log the plot to W&B\n",
        "viz_run.log({\"text_wordcloud\": wandb.Image(plt)})\n",
        "plt.show()\n",
        "\n",
        "# --- Word Cloud of Solutions ---\n",
        "solutions_corpus = ' '.join(df_scenario_outcome['solutions_pr '].astype(str).tolist())\n",
        "wordcloud_solutions = WordCloud(width=800, height=400, background_color='white').generate(solutions_corpus)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud_solutions, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud of Solutions Data')\n",
        "# Log the plot to W&B\n",
        "viz_run.log({\"solutions_wordcloud\": wandb.Image(plt)})\n",
        "plt.show()\n",
        "\n",
        "# --- Length Distribution of Text ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df_scenario_outcome['text_pr'].str.len(), bins=30)\n",
        "plt.title('Distribution of Text Length')\n",
        "plt.xlabel('Text Length')\n",
        "plt.ylabel('Frequency')\n",
        "# Log the plot to W&B\n",
        "viz_run.log({\"text_length_distribution\": wandb.Image(plt)})\n",
        "plt.show()\n",
        "\n",
        "# --- Correlation Heatmap (if applicable) ---\n",
        "# If you have numerical features, you can create a correlation heatmap\n",
        "# Example:\n",
        "# numeric_features = df_scenario_outcome[['column1', 'column2']]  # Replace with actual numerical columns\n",
        "# correlation_matrix = numeric_features.corr()\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "# plt.title('Correlation Heatmap')\n",
        "# viz_run.log({\"correlation_heatmap\": wandb.Image(plt)})\n",
        "# plt.show()\n",
        "\n",
        "# --- Create an artifact and save the visualizations ---\n",
        "artifact = wandb.Artifact(name=\"pre_finetuning_visualizations\", type=\"visualizations\")\n",
        "# Add any files you want to include in the artifact (e.g., images, data files)\n",
        "# artifact.add_file(\"path/to/your/file.png\")\n",
        "\n",
        "# Log the artifact to W&B\n",
        "viz_run.log_artifact(artifact)\n",
        "\n",
        "# Finish the visualization run\n",
        "viz_run.finish()\n"
      ],
      "metadata": {
        "id": "OSkcVP3MIpDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXJPD8DTafqf"
      },
      "source": [
        "# Preparing to Train\n",
        "1. Isolate important columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "openai.api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "from wandb.integration.openai.fine_tuning import WandbLogger\n",
        "data=f\"{BASE_URL}/{project}/{model_name}.jsonl\"\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "client.files.create(\n",
        "  file=open(\"mydata.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "# Finetuning logic\n",
        "id = uuid.uuidv4()\n",
        "if FINETUNE_JOB_ID == True:\n",
        "  WandbLogger.sync(project=fine_tune_job_id=FINETUNE_JOB_ID)\n",
        "\n",
        "\n",
        "WandbLogger.sync(entity=\"orion-agents-org\")"
      ],
      "metadata": {
        "id": "PzmimcUZGiOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAlTGdSA47Db"
      },
      "source": [
        "# Fine Tuning Using Different Approaches\n",
        "1. Open AI gpt-4o mini with small embeddings from OAI\n",
        "2. Open AI gpt-4o mini with Word2Vec\n",
        "\n",
        "1. Word2Vec model with Sentence Transformers\n",
        "\n",
        "** After we have the models we will train them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYJ7rAy-nUfI"
      },
      "outputs": [],
      "source": [
        "# prompt: train test split from sklearn 0.1 size , random_stat42\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df_train, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9LJpiMKGy8j"
      },
      "outputs": [],
      "source": [
        "### Need to concat the features.\n",
        "#System Messages : 1 Assistant\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"A ransomware attack encrypted critical files. Diagnosis: The attack vector was a phishing email. Solutions: 1. Isolate infected systems, 2. Pay the ransom, 3. Restore from backups.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Not advisable, 3. Good.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"Data breach exposing customer information. Diagnosis: Misconfigured cloud storage. Solutions: 1. Notify affected customers, 2. Implement stricter access controls, 3. Ignore the breach.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Good, 3. Bad.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"Unauthorized access to internal network. Diagnosis: Weak password policy. Solutions: 1. Change all passwords, 2. Implement MFA, 3. Monitor network traffic.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Good, 3. Good.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"DDoS attack causing service disruption. Diagnosis: Insufficient network defenses. Solutions: 1. Increase bandwidth, 2. Implement rate limiting, 3. Deploy DDoS protection service.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Partial, 2. Good, 3. Good.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"Malware infection on multiple devices. Diagnosis: Lack of antivirus software. Solutions: 1. Install antivirus software, 2. Perform a full system scan, 3. Disconnect infected devices from the network.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Good, 3. Good.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"Phishing attack leading to credential theft. Diagnosis: Lack of user training. Solutions: 1. Conduct phishing awareness training, 2. Change compromised credentials, 3. Implement email filtering.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Good, 3. Good.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"SQL injection attack compromising database. Diagnosis: Lack of input validation. Solutions: 1. Implement input validation, 2. Use parameterized queries, 3. Perform regular security audits.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Good, 3. Good.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"Unauthorized access to sensitive data. Diagnosis: Inadequate access controls. Solutions: 1. Restrict access to sensitive data, 2. Implement role-based access control, 3. Regularly review access logs.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Good, 3. Good.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"Insider threat leaking confidential information. Diagnosis: Lack of monitoring. Solutions: 1. Implement user activity monitoring, 2. Conduct background checks, 3. Establish a whistleblower policy.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Good, 3. Good.\"}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"For each scenario, there is a scenario with a diagnosis and solutions. Decide if they are good solutions.\"},\n",
        "            {\"role\": \"user\", \"content\": {\"scenario_outcome\": \"Zero-day exploit used in an attack. Diagnosis: Outdated software. Solutions: 1. Apply patches promptly, 2. Use intrusion detection systems, 3. Maintain an incident response plan.\"}},\n",
        "            {\"role\": \"assistant\", \"content\": \"By my assessment, the solutions were: 1. Good, 2. Good, 3. Good.\"}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyiRlOZW4I0W"
      },
      "outputs": [],
      "source": [
        "'''System Messages : Multiple Assistants\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris\", \"weight\": 0}, {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\", \"weight\": 1}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"William Shakespeare\", \"weight\": 0}, {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\", \"weight\": 1}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"384,400 kilometers\", \"weight\": 0}, {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\", \"weight\": 1}]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTbbfJzjZNA_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "#Define Template\n",
        "system_messages = [{sys}]\n",
        "prefix = {'messages':{\"role:\"system\", \"content\": \"Here are a variety of solutions to cyber problems. Analyze and give a binary 0 for no and 1 for yes.'}}}\n",
        "postfix =\n",
        "\n",
        "with open(\"./text_sql.json\", \"w\") as f:\n",
        "    json.dump(template, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMvcLAO3Y5uS"
      },
      "outputs": [],
      "source": [
        "# DF to JSON Serialized\n",
        "df_to_json = df_domain.to_json('./text_sql.json', orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeZ3bG6pxKVF"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(project=\"Cyber-Phi-Small-8k-instruct\", job_type=\"dataset\")\n",
        "artifact = wandb.Artifact(name=\"df_to_json\", type=\"dataset\")\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEoFsHZTwIcr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFuQfrG9a7Yd"
      },
      "source": [
        "## Model Training\n",
        "1. Tokenize with TikToken\n",
        "2. @ 4bit for improved speed traded off for lower precision calculation on weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2KJagoGdb-h"
      },
      "outputs": [],
      "source": [
        "run2 = wandb.init(project=\"Cyber-Phi-Small-8k-instruct\", job_type=\"train\")\n",
        "run3 = wandb.init(project=\"gpt4o-mini\", job_type=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e6F9rY2hyqE"
      },
      "outputs": [],
      "source": [
        "# Load model directly from HuggingFace\n",
        "%pip install -qq tiktoken einops\n",
        "%pip install  -q torch==2.2.2+cu121 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 torchtext==0.15.2 torchdata==0.6.1 --extra-index-url https://download.pytorch.org/whl/cu121 -U\n",
        "_logger.info(device)\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import tiktoken\n",
        "import einops\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Phi-3-small-8k-instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    #token = os.getenv(\"WANDB_API_KEY\"), # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6qjVeh_CcoL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5hCZXRw9SpZ"
      },
      "source": [
        "### Extract Entities for Graph\n",
        "1. Make new dataFrame wth text an relations broken down, then labelled with Node or Relationship.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X0w3Wj09SEY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "df_Graph = df_train.copy()\n",
        "def graph_df(text):\n",
        "  columns = text.unique()\n",
        "  graph_df=pd.DataFrame(columns=columns)\n",
        "  return graph_df\n",
        "print(df_Graph.head())\n",
        "graph_df = graph_df(df_Graph['entities'])\n",
        "graph_df.shape\n",
        "new_df = pd.DataFrame(columns=graph_df[0::])\n",
        "new_df.head()\n",
        "for k, v in enumerate(new_df.index):\n",
        "  print(f'k is {k} and v is {v}')\n",
        "  print(v)\n",
        "  #new_df[f\"{v}\"] = df_Graph['entities'][k].split(',')\n",
        "  #print(new_df[f\"{v}]\"])\n",
        "  #print(graph_df.head())\n",
        "\n",
        "#print(graph_df.describe)\n",
        "#print(graph_df.head())\n",
        "#print(np.array_split(values=graph_df,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MNsHmHxiAi-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6D5oLNFhyXM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvAi_yUZZrOW"
      },
      "outputs": [],
      "source": [
        "def load_and_log():\n",
        "\n",
        "    # üöÄ start a run, with a type to label it and a project it can call home\n",
        "    with wandb.init(project=\"artifacts-data-models\", job_type=\"load-data\") as run:\n",
        "\n",
        "        datasets = load()  # separate code for loading the datasets\n",
        "        names = [\"training\", \"validation\", \"test\"]\n",
        "\n",
        "        # üè∫ create our Artifact\n",
        "        raw_data = wandb.Artifact(\n",
        "            \"cyber-phi\", type=\"dataset\",\n",
        "            description=\"Cyber-Phi\",\n",
        "            metadata={\"source\": \"torchvision.datasets.MNIST\",\n",
        "                      \"sizes\": [len(dataset) for dataset in datasets]})\n",
        "\n",
        "        for name, data in zip(names, datasets):\n",
        "            # üê£ Store a new file in the artifact, and write something into its contents.\n",
        "            with raw_data.new_file(name + \".pt\", mode=\"wb\") as file:\n",
        "                x, y = data.tensors\n",
        "                torch.save((x, y), file)\n",
        "\n",
        "        # ‚úçÔ∏è Save the artifact to W&B.\n",
        "        run.log_artifact(raw_data)\n",
        "\n",
        "load_and_log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8PHxUZ3fR-d"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNiHj2N-daW4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "###APPENDIX A\n",
        "\n",
        "### ü§óFine-Tuning Techniques: ü§ó\n",
        "\n",
        "**PEFT** (Parameter-Efficient Fine-Tuning): Fine-tunes pre-trained models by adjusting only a small subset of parameters, reducing computational costs.\n",
        "\n",
        "**LoRA** (Low-Rank Adaptation): Enhances transformer models by injecting and training low-rank matrices within each layer, minimizing the number of trainable parameters.\n",
        "\n",
        "**QLoRA** (Quantized Low-Rank Adaptation): Combines low-rank adaptation with weight quantization to achieve efficient fine-tuning with reduced memory and computational requirements.\n",
        "\n",
        "**Full Fine-Tuning:** Updates all parameters of the pre-trained model, offering high flexibility at the cost of increased computational resources.\n",
        "\n",
        "**Distillation:** Trains a smaller model to mimic the behavior of a larger pre-trained model, optimizing efficiency while maintaining performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "history_visible": true,
      "mount_file_id": "1Am35ve-nPrxv-_NIz4-a8IhcQWjfM-u0",
      "authorship_tag": "ABX9TyNvOvSHMfJ2zeH+T+5nAZAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f82834ac892c431abe7822013c126ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72d168cc729e4d8cb62eaeefef024443",
              "IPY_MODEL_4acedea27780456e950a0737d76102a8",
              "IPY_MODEL_99de622c529e4ec6b9887ee751f199ff"
            ],
            "layout": "IPY_MODEL_a30a30900ff04a64b4097f7b6b3f8ff0"
          }
        },
        "72d168cc729e4d8cb62eaeefef024443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a145abca4b748a699a4757e19c7dfe6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4d582e1a11874a39b3c1e8f295ca32f2",
            "value": "Downloading‚Äáreadme:‚Äá100%"
          }
        },
        "4acedea27780456e950a0737d76102a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1be3d87fa864880b9dd1fa2964a30a7",
            "max": 84,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5d7f507376e4ee5826116f8f8a786bc",
            "value": 84
          }
        },
        "99de622c529e4ec6b9887ee751f199ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52bfe86a981f4034876afc6dd3bf58fc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c900153801b44462a1c9040c543dd805",
            "value": "‚Äá84.0/84.0‚Äá[00:00&lt;00:00,‚Äá8.80kB/s]"
          }
        },
        "a30a30900ff04a64b4097f7b6b3f8ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a145abca4b748a699a4757e19c7dfe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d582e1a11874a39b3c1e8f295ca32f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1be3d87fa864880b9dd1fa2964a30a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d7f507376e4ee5826116f8f8a786bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52bfe86a981f4034876afc6dd3bf58fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c900153801b44462a1c9040c543dd805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d53609428a43bda29255f681429e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c44fe28d498422d8ce285c7b145d36e",
              "IPY_MODEL_895dcea02b9a49b4913a860a149b1ea6",
              "IPY_MODEL_554b3054da304853b3964b02acb779f2"
            ],
            "layout": "IPY_MODEL_a9d755e6780c46ec915f20d2178fb542"
          }
        },
        "5c44fe28d498422d8ce285c7b145d36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d417d23b67074b6d8ac0b9c237e12dee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e956c02111014b19a4ed384ebe707ba6",
            "value": "Downloading‚Äádata:‚Äá100%"
          }
        },
        "895dcea02b9a49b4913a860a149b1ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7583152e609442f89e523da1656f168",
            "max": 685490,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e8640c063b54906a972fc1402a822d3",
            "value": 685490
          }
        },
        "554b3054da304853b3964b02acb779f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f351673975b4ba9a8e6126cd3eedfe4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8853d220d7a848688ba352787220735e",
            "value": "‚Äá685k/685k‚Äá[00:00&lt;00:00,‚Äá1.49MB/s]"
          }
        },
        "a9d755e6780c46ec915f20d2178fb542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d417d23b67074b6d8ac0b9c237e12dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e956c02111014b19a4ed384ebe707ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7583152e609442f89e523da1656f168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e8640c063b54906a972fc1402a822d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f351673975b4ba9a8e6126cd3eedfe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8853d220d7a848688ba352787220735e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abd9ee925c7145179f749ec68f2ceb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fde5772136d4250a1818d73932e9fdc",
              "IPY_MODEL_72ad568cf8914ef19ff82b33868559cd",
              "IPY_MODEL_79880035f72c456893bc4dfa13620900"
            ],
            "layout": "IPY_MODEL_96f2868a0d134f219619242c8105885d"
          }
        },
        "7fde5772136d4250a1818d73932e9fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14d082d3946043b2b9f4ac43bf9506a3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1b3605def8e743daac25d5984e5fdb5d",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "72ad568cf8914ef19ff82b33868559cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b974d6a7da04cb59a7c8af4ae8b0570",
            "max": 476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3835b431363d454d95e5674611633a71",
            "value": 476
          }
        },
        "79880035f72c456893bc4dfa13620900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca78d49634f04fdc951be76b8c5bcba8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8bcc46bb333f49c4a2bd0938b342c498",
            "value": "‚Äá476/476‚Äá[00:00&lt;00:00,‚Äá9463.83‚Äáexamples/s]"
          }
        },
        "96f2868a0d134f219619242c8105885d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d082d3946043b2b9f4ac43bf9506a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b3605def8e743daac25d5984e5fdb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b974d6a7da04cb59a7c8af4ae8b0570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3835b431363d454d95e5674611633a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca78d49634f04fdc951be76b8c5bcba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bcc46bb333f49c4a2bd0938b342c498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077e0aae1b25438ca429d731dd980c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d17d9126bc3349549aa54d2c96f3b09e",
              "IPY_MODEL_2e72689caa79421782caeb102860eb39",
              "IPY_MODEL_0500f9571a6941029dfbb0ef573842e9"
            ],
            "layout": "IPY_MODEL_8176a636edf24125beb39abde56db33a"
          }
        },
        "d17d9126bc3349549aa54d2c96f3b09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a8907e67b594656ab4ad706f4b55da9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f7be7dced194d188646ad035a4019f9",
            "value": "100%"
          }
        },
        "2e72689caa79421782caeb102860eb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52cbfcf2c449409ba71b13aa8900ac74",
            "max": 476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3bf3637a1574c1ab27ee30cd046e0c1",
            "value": 476
          }
        },
        "0500f9571a6941029dfbb0ef573842e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b690c30e65e493b9e28c3840d67665d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fb579b754b0e4fb7966956a2db25fc7a",
            "value": "‚Äá476/476‚Äá[00:00&lt;00:00,‚Äá40933.46it/s]"
          }
        },
        "8176a636edf24125beb39abde56db33a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a8907e67b594656ab4ad706f4b55da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f7be7dced194d188646ad035a4019f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52cbfcf2c449409ba71b13aa8900ac74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3bf3637a1574c1ab27ee30cd046e0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b690c30e65e493b9e28c3840d67665d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb579b754b0e4fb7966956a2db25fc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c4900b089d848f6b1d85a863f593b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d7bdf13531647cfbad0f83e53341682",
              "IPY_MODEL_43b75bdaf780490986b89e4869782db9",
              "IPY_MODEL_daeac61738644eecbd9c9531d449fa3c"
            ],
            "layout": "IPY_MODEL_e6d869e58dbb4bea91926f2263ab4fc6"
          }
        },
        "5d7bdf13531647cfbad0f83e53341682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c035efe94f3f4ce28d40a7d63aedd411",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_793bfd2ea2e047e9b6f1066b849a1181",
            "value": "100%"
          }
        },
        "43b75bdaf780490986b89e4869782db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aadd29e0afa40b1875e07e9b2afac4e",
            "max": 476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b2ebfb8bdcd4a5ca51bb6d65cab9cda",
            "value": 476
          }
        },
        "daeac61738644eecbd9c9531d449fa3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b7d7628a2749b399fe4a7de92cfefb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0dffe6cbe1f3429cb924a44622bb69a8",
            "value": "‚Äá476/476‚Äá[00:00&lt;00:00,‚Äá46062.54it/s]"
          }
        },
        "e6d869e58dbb4bea91926f2263ab4fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c035efe94f3f4ce28d40a7d63aedd411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "793bfd2ea2e047e9b6f1066b849a1181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aadd29e0afa40b1875e07e9b2afac4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2ebfb8bdcd4a5ca51bb6d65cab9cda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32b7d7628a2749b399fe4a7de92cfefb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dffe6cbe1f3429cb924a44622bb69a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6f248eb6b814d119dba522ddec9745a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7169f98bfa34f29aba44c64982f0a2d",
              "IPY_MODEL_bc957928ee25442aab5cf7c720dbb441",
              "IPY_MODEL_d7bf2660d8d640ee88091a9748165d64"
            ],
            "layout": "IPY_MODEL_a005ec56a1a04ae1b6337b85cdbaf4d3"
          }
        },
        "e7169f98bfa34f29aba44c64982f0a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc098ef691e44a168b1bc4de43eb43e8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ee6a6a2a5f5d4bfcb5d5949d8bc5c32a",
            "value": "100%"
          }
        },
        "bc957928ee25442aab5cf7c720dbb441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e30068c3abe4f6495471f9af8450540",
            "max": 476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f946490fd894258802b6339e4a3e696",
            "value": 476
          }
        },
        "d7bf2660d8d640ee88091a9748165d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_393cb25369254352b8ed9b5468f1be9b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b3bee792942e4dd5af9c90589b5a72dd",
            "value": "‚Äá476/476‚Äá[00:00&lt;00:00,‚Äá30861.45it/s]"
          }
        },
        "a005ec56a1a04ae1b6337b85cdbaf4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc098ef691e44a168b1bc4de43eb43e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6a6a2a5f5d4bfcb5d5949d8bc5c32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e30068c3abe4f6495471f9af8450540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f946490fd894258802b6339e4a3e696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "393cb25369254352b8ed9b5468f1be9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3bee792942e4dd5af9c90589b5a72dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}